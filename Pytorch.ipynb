{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c677f8af-bf46-41b3-b991-2b2dc684d361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.Tensor([5,3])\n",
    "y = torch.Tensor([2,1])\n",
    "\n",
    "print(x*y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa0eb1eb-1fe3-48f7-9086-71c652692ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]]) \n",
      " torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros([2,5])\n",
    "print(x,\"\\n\",x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c70a716b-a821-4f9b-8191-98a6c399e8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8534, 0.8300, 0.5476, 0.9083, 0.6344],\n",
       "        [0.4390, 0.0590, 0.9487, 0.5176, 0.9437]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand([2,5])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3503709-e51a-4a6f-9266-fbf5a1326698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8534, 0.8300, 0.5476, 0.9083, 0.6344, 0.4390, 0.0590, 0.9487, 0.5176,\n",
       "         0.9437]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view([1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d9dded-6b59-48a2-a445-2efb41d17232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8534, 0.8300, 0.5476, 0.9083, 0.6344],\n",
      "        [0.4390, 0.0590, 0.9487, 0.5176, 0.9437]])\n"
     ]
    }
   ],
   "source": [
    "print(y) # y is same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56e38bad-352e-4bd1-b067-bc0b3921f460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8534, 0.8300, 0.5476, 0.9083, 0.6344, 0.4390, 0.0590, 0.9487, 0.5176,\n",
       "        0.9437])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfacb01e-a1b2-41ba-88fa-c04312078a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8534, 0.8300, 0.5476, 0.9083, 0.6344],\n",
      "        [0.4390, 0.0590, 0.9487, 0.5176, 0.9437]])\n"
     ]
    }
   ],
   "source": [
    "print(y) # still same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47dfe397-d6d4-496d-869b-ec1248f45ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Check if CUDA (GPU) is available\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"CUDA is available. GPU is available.\")\n",
    "#     print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "#     print(f\"Current GPU: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "# else:\n",
    "#     print(\"CUDA is not available. GPU is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ff0535b-9b40-40e3-a5fd-f95b69e1fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "116d442f-2eae-4402-9f31-77537c877ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bc279a7-1bb6-4bbb-ba21-5238ab32f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0b51ee4-faa9-4a22-bb6a-cf874d5932b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 4, 8, 2, 1, 2, 5, 7, 4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for data in trainset:\n",
    "    x, y = data\n",
    "    print(y)\n",
    "    \n",
    "    # Take the first image from the batch and visualize it\n",
    "    img = x[0]\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.show()\n",
    "    break  # Remove this break statement to visualize more images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741668d-949a-4f21-8abe-fa02e83c51bc",
   "metadata": {},
   "source": [
    "## Building Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19e50cc1-ef02-4e62-a78b-f75ef85f34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b796b294-f713-4817-84d0-bc9488ac7bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8645b42-2f2d-41dd-ac33-2b81f6ae27b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1339, -2.3907, -2.2351, -2.2992, -2.4206, -2.4782, -2.1840, -2.1986,\n",
      "         -2.3424, -2.4041]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((28,28))\n",
    "print(net.forward(x.view(-1,28*28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cb019-4379-49cf-bcfe-69fadffe2091",
   "metadata": {},
   "source": [
    "## Gradients\n",
    "\n",
    "The `net.zero_grad()` function is a crucial step in the training loop of a neural network using PyTorch. To understand its importance, let's break down what it does and why it's necessary:\n",
    "\n",
    "### What `net.zero_grad()` Does:\n",
    "`net.zero_grad()` resets the gradients of all the model parameters to zero. In PyTorch, the gradients are accumulated by default, which means that they are not automatically reset after each backward pass (backpropagation). Instead, they are added to the existing gradients.\n",
    "\n",
    "### Why Zeroing Gradients is Necessary:\n",
    "During the training of a neural network, the following steps are typically performed in each iteration of the training loop:\n",
    "1. **Forward Pass**: Compute the model's output for the given input data.\n",
    "2. **Compute Loss**: Calculate the loss (error) between the model's output and the true labels.\n",
    "3. **Backward Pass**: Perform backpropagation to compute the gradients of the loss with respect to the model parameters.\n",
    "4. **Update Parameters**: Update the model parameters using the computed gradients.\n",
    "\n",
    "If you do not zero the gradients before the backward pass, the gradients from the previous batch will be accumulated with the gradients from the current batch. This will lead to incorrect updates of the model parameters because the gradients will not reflect the true gradient of the loss for the current batch. \n",
    "\n",
    "### Example Training Loop:\n",
    "Here is how the training loop should look including `net.zero_grad()` and the other steps mentioned:\n",
    "\n",
    "```python\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Assuming a classification task\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = net(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass (compute gradients)\n",
    "        optimizer.step()  # Update parameters\n",
    "```\n",
    "\n",
    "### Key Points:\n",
    "1. **Forward Pass**: `outputs = net(inputs)` computes the model's predictions.\n",
    "2. **Compute Loss**: `loss = criterion(outputs, labels)` calculates the loss.\n",
    "3. **Backward Pass**: `loss.backward()` computes the gradients of the loss with respect to each parameter.\n",
    "4. **Update Parameters**: `optimizer.step()` updates the model parameters using the computed gradients.\n",
    "5. **Zero Gradients**: `optimizer.zero_grad()` or `net.zero_grad()` resets the gradients before the next iteration.\n",
    "\n",
    "### Why Use `optimizer.zero_grad()` Instead of `net.zero_grad()`:\n",
    "- `optimizer.zero_grad()` is preferred because it ensures that gradients of all the parameters that the optimizer is responsible for are zeroed out. This is especially useful if you have multiple optimizers or if not all parameters of the model are being optimized by a single optimizer.\n",
    "- If you use `net.zero_grad()`, it will zero out the gradients of all parameters in `net`, regardless of whether they are being optimized by the current optimizer. \n",
    "\n",
    "In most cases, both will work fine if you are dealing with a single model and a single optimizer. However, using `optimizer.zero_grad()` is generally recommended for clarity and safety in more complex setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07b3f4be-0fd7-482c-abf5-3850a715bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1540, grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(0.2820, grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(0.0023, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        x,y = data\n",
    "        net.zero_grad()\n",
    "        output = net(x.view(-1,28*28))\n",
    "        loss = F.nll_loss(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Loss:\",loss)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06a2b834-9f60-45d6-9f0c-c2d5c33a79ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.971\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): # don't calculate gradients here\n",
    "    for data in testset:\n",
    "        x,y = data \n",
    "        output = net(x.view(-1,28*28))\n",
    "        for idx,i in enumerate(output):\n",
    "            if torch.argmax(i)==y[idx]:\n",
    "                correct+=1\n",
    "            total+=1\n",
    "print(\"Accuracy: \",round(correct/total,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "712c45ee-6ea2-4c16-977e-02bb991fbfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9707 10000\n"
     ]
    }
   ],
   "source": [
    "print(correct,total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee21d0-6a0f-4786-ac44-0b0a1cf40dd5",
   "metadata": {},
   "source": [
    "## Convolution Nueral Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e384c-1a54-424f-a509-b96ad4f4b73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
