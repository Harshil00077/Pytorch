{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01786b3-7f37-4b62-a04d-1ec0a308aea9",
   "metadata": {},
   "source": [
    "## Convolution Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bcd4d1a-b1fd-4a9a-a083-895d7a22bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "Rebuild_Data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "284794a9-0ce8-40b8-8b9a-23b2bd5dea2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e9f1c0-6c18-4462-b949-15253047af13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DogsVSCats:\n",
    "    IMG_SIZE = (50, 50)\n",
    "    CATS = \"../PetImages/Cat\"\n",
    "    DOGS = \"../PetImages/Dog\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.training_data = []\n",
    "        self.catcount = 0\n",
    "        self.dogcount = 0\n",
    "        self.hg_data = []\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                path = os.path.join(label, f)\n",
    "                img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                one_hot_label = np.eye(2)[self.LABELS[label]]\n",
    "               \n",
    "\n",
    "                if img is not None:\n",
    "                    try:\n",
    "                        img = cv2.resize(img, self.IMG_SIZE)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to process {f}: {e}\")\n",
    "                        continue  # Skip this image if an error occurs\n",
    "                    self.training_data.append(np.array([np.array(img), one_hot_label],dtype=\"object\"))\n",
    "                    if label == self.CATS:\n",
    "                        self.catcount += 1\n",
    "                    elif label == self.DOGS:\n",
    "                        self.dogcount += 1\n",
    "\n",
    "        for data in tqdm(self.training_data):\n",
    "            if (len(data) == 2 and isinstance(data[0], np.ndarray) and data[0].shape == self.IMG_SIZE and isinstance(data[1], np.ndarray) and data[1].shape == (2,)):\n",
    "                self.hg_data.append(data)\n",
    "            else:\n",
    "                print(f\"Skipping inhomogeneous element: {data}\")\n",
    "\n",
    "        # Save the homogeneous data with allow_pickle=True\n",
    "        np.save(\"../training_data.npy\",self.hg_data, allow_pickle=True)\n",
    "        print(\"Cats:\", self.catcount)\n",
    "        print(\"Dogs:\", self.dogcount)\n",
    "\n",
    "# Example usage\n",
    "Rebuild_Data = False\n",
    "if Rebuild_Data:\n",
    "    dataset = DogsVSCats()\n",
    "    dataset.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e86f68d-35d1-44c1-be2e-354b661b4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(\"../training_data.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2a1c759-92f5-4bc7-bae1-7827aec7fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5d7f35-5f6e-4853-a31b-65fd48a0d76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 44,  60,  41, ...,  95,  94, 197],\n",
      "        [ 41,  43,  43, ...,  93,  80, 192],\n",
      "        [ 41,  40,  46, ...,  90,  86, 193],\n",
      "        ...,\n",
      "        [ 25,  21,  26, ...,  43,  67,  73],\n",
      "        [ 21,  23,  21, ...,  74,  36,  89],\n",
      "        [ 23,  22,  20, ...,  59,  62,  32]], dtype=uint8) array([1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6b60446-a640-45a3-a404-97bc8f7c8c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(training_data[11][0],cmap=\"gray\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6cd56a-eaa4-4fdf-a612-6f89894313e2",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97facfe7-1655-4eb7-9fdd-2a9a5602a651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1, 50, 50])\n",
      "After conv1: torch.Size([1, 32, 46, 46])\n",
      "After pool1: torch.Size([1, 32, 23, 23])\n",
      "After conv2: torch.Size([1, 64, 19, 19])\n",
      "After pool2: torch.Size([1, 64, 9, 9])\n",
      "After conv3: torch.Size([1, 128, 5, 5])\n",
      "After pool3: torch.Size([1, 128, 2, 2])\n",
      "After flatten: torch.Size([1, 512])\n",
      "After fc1: torch.Size([1, 16])\n",
      "After fc2: torch.Size([1, 2])\n",
      "Output: tensor([[-0.0262,  0.1153]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, 1)  # 5x5 kernel, 1 input channel, 32 output channels\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1) # 5x5 kernel, 32 input channels, 64 output channels\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, 1) # 5x5 kernel, 64 input channels, 128 output channels\n",
    "        # Calculate the flattened size after conv and pooling layers.\n",
    "        self.fc1 = nn.Linear(128 * 2 * 2, 16)  # Update the input size accordingly\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input shape:\", x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        print(\"After conv1:\", x.shape)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        print(\"After pool1:\", x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        print(\"After conv2:\", x.shape)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        print(\"After pool2:\", x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        print(\"After conv3:\", x.shape)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        print(\"After pool3:\", x.shape)\n",
    "        x = x.view(-1, 128 * 2 * 2)  # Flatten the tensor\n",
    "        print(\"After flatten:\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(\"After fc1:\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        print(\"After fc2:\", x.shape)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "net = Net()\n",
    "\n",
    "# Create a dummy input tensor with shape (batch_size, channels, height, width)\n",
    "dummy_input = torch.randn(1, 1, 50, 50)  # Batch size of 1, 1 channel, 50x50 image\n",
    "\n",
    "output = net.forward(dummy_input)\n",
    "print(\"Output:\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447683ad-da37-40d9-8158-6062b1e4da24",
   "metadata": {},
   "source": [
    "#\n",
    "#\n",
    "# Hidden Layers\n",
    "\n",
    "**Role:**\n",
    "- The hidden layers transform the input data into a space where the patterns relevant to the problem can be more easily separated.\n",
    "- These layers create complex, non-linear mappings of the input data.\n",
    "\n",
    "## **Common Activation Functions:**\n",
    "## $ \\text{ReLU}(x) = \\max(0, x) $\n",
    "  - Pros: Helps with the vanishing gradient problem, computationally efficient.\n",
    "  - Cons: Can suffer from the \"dying ReLU\" problem where neurons can get stuck during training.\n",
    "## $ \\text{Sigmoid}(x) = \\frac{1}{1 + e^{-x}} $\n",
    "  - Pros: Outputs values between 0 and 1, can be interpreted as probabilities.\n",
    "  - Cons: Can cause vanishing gradient problems.\n",
    "## $ \\text{Tanh}(x) =  \\frac{e^x - e^{-x}}{e^x + e^{-x}} $\n",
    "  - Pros: Outputs values between -1 and 1, zero-centered.\n",
    "  - Cons: Also suffers from vanishing gradient issues.\n",
    "\n",
    "# Output Layers\n",
    "\n",
    "**Role:**\n",
    "- The output layer produces the final result of the neural network, which could be a classification, a regression value, etc.\n",
    "- Different problems require different output ranges and interpretations.\n",
    "\n",
    "# **Common Activation Functions for Output Layers:**\n",
    "## **Softmax:** Typically used in multi-class classification problems.\n",
    "> ## $ \\text{Softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}} $\n",
    "  - Pros: Converts logits into probabilities that sum to 1.\n",
    "  - Cons: Not suitable for regression tasks.\n",
    "## **Sigmoid:** Often used in binary classification problems.\n",
    "> ## $ \\text{Sigmoid}(x) = \\frac{1}{1 + e^{-x}} $\n",
    "  - Pros: Outputs values between 0 and 1.\n",
    "  - Cons: Limited to binary outcomes.\n",
    "## **Linear:** Used in regression problems.\n",
    "> ## $ \\text{Linear}(x) = x $\n",
    "  - Pros: Suitable for predicting continuous values.\n",
    "  - Cons: Not suitable for classification tasks.\n",
    "\n",
    "# Why Not Use ReLU in the Output Layer?\n",
    "\n",
    "**ReLU Characteristics:**\n",
    "- Outputs any positive value as itself and zero for any negative input.\n",
    "- Not bounded, meaning its output range is $[0, \\infty)$.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "1. **Classification Problem:**\n",
    "   - If you use ReLU in the output layer for a classification problem (e.g., a multi-class classification task), you would get non-negative outputs but not probabilities. Classification typically requires interpreting the output as probabilities, which should sum to 1. ReLU cannot naturally enforce this constraint, unlike the Softmax function.\n",
    "\n",
    "2. **Regression Problem:**\n",
    "   - For regression tasks, using ReLU could limit the range of the output to non-negative values only. This might not be desirable if the target values can be negative. For example, predicting house prices could work with ReLU if prices are always positive, but predicting temperature, which can be negative, would be inappropriate with ReLU.\n",
    "\n",
    "### Detailed Example: Multi-Class Classification\n",
    "\n",
    "Consider a neural network designed to classify images into one of three categories: Cat, Dog, and Bird. The final layer must output a probability distribution over these three classes.\n",
    "\n",
    "**Using ReLU in the Output Layer:**\n",
    "- The network might output values like [2.5, 0, 3.7] for an input image.\n",
    "- These values are not probabilities and do not sum to 1.\n",
    "- There's no straightforward way to interpret these values as the likelihood of each class.\n",
    "\n",
    "**Using Softmax in the Output Layer:**\n",
    "- The network might output logits [2.5, 0, 3.7].\n",
    "- After applying Softmax, these logits might convert to probabilities like [0.28, 0.01, 0.71].\n",
    "- These probabilities sum to 1, making it clear that the model predicts \"Bird\" with 71% confidence.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The choice of activation function in the output layer is crucial and must align with the problem requirements. While ReLU is excellent for hidden layers due to its properties that help mitigate issues like the vanishing gradient problem, it is not suitable for output layers in many cases because it does not provide a bounded, interpretable output suitable for classification or regression tasks. Different tasks necessitate different activation functions to ensure the outputs are meaningful and useful for the specific application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56831888-46f8-4351-8d8e-aa5948188a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "Output: tensor([[0.4988, 0.5012]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 5, 1)  # 5x5 kernel, 1 input channel, 32 output channels\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 5, 1) # 5x5 kernel, 32 input channels, 64 output channels\n",
    "#         self.conv3 = nn.Conv2d(64, 128, 5, 1) # 5x5 kernel, 64 input channels, 128 output channels\n",
    "#         # Calculate the flattened size after conv and pooling layers.\n",
    "#         self.fc1 = nn.Linear(128 * 2 * 2, 16)  # Update the input size accordingly\n",
    "#         self.fc2 = nn.Linear(16, 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.max_pool2d(x, 2, 2)\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.max_pool2d(x, 2, 2)\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         x = F.max_pool2d(x, 2, 2)\n",
    "#         x = x.view(-1, 128 * 2 * 2)  \n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return F.softmax(x,dim=1)\n",
    "\n",
    "# # Example usage\n",
    "# net = Net()\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "# Create a dummy input tensor with shape (batch_size, channels, height, width)\n",
    "dummy_input = torch.randn(1, 1, 50, 50)  # Batch size of 1, 1 channel, 50x50 image\n",
    "\n",
    "output = net.forward(dummy_input)\n",
    "print(\"Output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c82cda75-482a-4a7f-90f7-cd9dfc017bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\opdar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\opdar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),0.0001)\n",
    "loss_function = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f46b446-ba88-400f-807f-c946b879440d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\opdar\\AppData\\Local\\Temp\\ipykernel_18664\\3353633519.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ad9152-464c-47ad-9146-53cef3eaabc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n"
     ]
    }
   ],
   "source": [
    "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae847a5-6298-4488-afa9-0d56b3ec1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=val_size, random_state=42)\n",
    "\n",
    "# train_X and train_y will contain data for training\n",
    "# test_X and test_y will contain data for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77ad59-8fc2-4da8-b6c7-51927cbebbe8",
   "metadata": {},
   "source": [
    "The main difference between `model.zero_grads()` and `optimizer.zero_grads()` lies in the scope of the operation:\r\n",
    "\r\n",
    "- `model.zero_grads()`: This method zeroes the gradients of all parameters in the model. It directly operates on the model itself, making it suitable for cases where you want to manually manage the gradient clearing process within the model.\r\n",
    "\r\n",
    "- `optimizer.zero_grads()`: On the other hand, this method zeroes the gradients of only the parameters that the optimizer is responsible for updating. It operates on the optimizer object and is commonly used during the training loop after the backward pass to clear gradients before the optimizer updates the model parametmized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973efb3-d5e5-4d71-b989-167da8f9f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "        #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "        net.zero_grad()\n",
    "\n",
    "        outputs = net(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        if i%10000==0:\n",
    "            print(batch_X)\n",
    "            print(outputs,batch_y)\n",
    "            print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055558b6-d709-411e-bd66-cc9b1a413723",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_X[i].view(-1, 1, 50, 50))[0]  # returns a list, \n",
    "        predicted_class = torch.argmax(net_out)\n",
    "\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7eaf01-6b62-466f-9211-e57fe1ae13ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
